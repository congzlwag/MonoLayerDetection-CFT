{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dce5f5f-76fa-4b71-a0fb-fefc95eeaaae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "YOLOv5 ðŸš€ bb2b687 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=True, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='models/transformer/yolov5n_transformerx01fuse.yaml', data='./data/multispectral/PLVIS2D.yaml', device='', entity=None, epochs=1, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1760  models.common.Focus                     [3, 16, 3]                    \n",
      "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  4                -1  1     39552  models.common.C3                        [64, 64, 3]                   \n",
      "  5                -4  1      1760  models.common.Focus                     [3, 16, 3]                    \n",
      "  6                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  7                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  8                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  9                -1  1     39552  models.common.C3                        [64, 64, 3]                   \n",
      " 10                 4  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 11                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      " 12                 9  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 13                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      " 14          [11, 13]  1   1602816  models.common.GPT                       [128]                         \n",
      " 15          [11, 14]  1         0  models.common.Add2                      [128, 0]                      \n",
      " 16          [13, 14]  1         0  models.common.Add2                      [128, 1]                      \n",
      " 17          [15, 16]  1         0  models.common.Add                       [128]                         \n",
      " 18                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      " 19                -1  1    164608  models.common.SPP                       [256, 256, [5, 9, 13]]        \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21            [4, 9]  1         0  models.common.Add                       [64]                          \n",
      " 22                20  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 23                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 24          [-1, 17]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 26                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      " 27                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 28          [-1, 21]  1         0  models.common.Concat                    [1]                           \n",
      " 29                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 30                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 31          [-1, 26]  1         0  models.common.Concat                    [1]                           \n",
      " 32                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
      " 33                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 34          [-1, 22]  1         0  models.common.Concat                    [1]                           \n",
      " 35                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 36      [29, 32, 35]  1      9471  models.yolo_test.Detect                 [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
      "Model Summary: 534 layers, 3680063 parameters, 3680063 gradients\n",
      "\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 154 .bias, 154 conv.weight, 86 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning RGB '../datasets/PLVIS2D/labels/train.rgb.cache' images and labels... 996 found, 0 missing, 50 empty, 0 corrupted\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning IR '../datasets/PLVIS2D/labels/train.ir.cache' images and labels... 996 found, 0 missing, 50 empty, 0 corrupted\n",
      "1.0\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning RGB '../datasets/PLVIS2D/labels/val.rgb.cache' images and labels... 109 found, 0 missing, 6 empty, 0 corrupted\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning IR '../datasets/PLVIS2D/labels/val.ir.cache' images and labels... 109 found, 0 missing, 6 empty, 0 corrupted\n",
      "Plotting labels... \n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 5.76, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 640 train, 640 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to runs/train/exp\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
      "  0%|                                                    | 0/32 [00:00<?, ?it/s]/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "       0/0     2.04G    0.1024   0.02644    0.0256    0.1544         8       640\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         109           0           0           0           0           0           0\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/seaborn/matrix.py:194: RuntimeWarning: All-NaN slice encountered\n",
      "  vmin = np.nanmin(calc_data)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/seaborn/matrix.py:199: RuntimeWarning: All-NaN slice encountered\n",
      "  vmax = np.nanmax(calc_data)\n",
      "1 epochs completed in 0.026 hours.\n",
      "\n",
      "Optimizer stripped from runs/train/exp/weights/last.pt, 7.7MB\n",
      "Optimizer stripped from runs/train/exp/weights/best.pt, 7.7MB\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --img 640 --batch 32 --epochs 1 --adam \\\n",
    "--data PLVIS2D.yaml --cfg models/transformer/yolov5n_transformerx01fuse.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a43de711-3637-4be9-aff8-0c36abc1b68d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "YOLOv5 ðŸš€ bb2b687 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Namespace(adam=True, artifact_alias='latest', batch_size=32, bbox_interval=-1, bucket='', cache_images=False, cfg='models/transformer/yolov5n_fusion_transformerx3.yaml', data='./data/multispectral/PLVIS2D.yaml', device='', entity=None, epochs=100, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[640, 640], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp8', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=32, upload_dataset=False, weights='', workers=8, world_size=1)\n",
      "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      1760  models.common.Focus                     [3, 16, 3]                    \n",
      "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  4                -1  1     39552  models.common.C3                        [64, 64, 3]                   \n",
      "  5                -4  1      1760  models.common.Focus                     [3, 16, 3]                    \n",
      "  6                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  7                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  8                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  9                -1  1     39552  models.common.C3                        [64, 64, 3]                   \n",
      " 10            [4, 9]  1    408192  models.common.GPT                       [64]                          \n",
      " 11           [4, 10]  1         0  models.common.Add2                      [64, 0]                       \n",
      " 12           [9, 10]  1         0  models.common.Add2                      [64, 1]                       \n",
      " 13                11  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 14                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      " 15                12  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      " 16                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
      " 17          [14, 16]  1   1602816  models.common.GPT                       [128]                         \n",
      " 18          [14, 17]  1         0  models.common.Add2                      [128, 0]                      \n",
      " 19          [16, 17]  1         0  models.common.Add2                      [128, 1]                      \n",
      " 20                18  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      " 21                -1  1    164608  models.common.SPP                       [256, 256, [5, 9, 13]]        \n",
      " 22                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 23                19  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      " 24                -1  1    164608  models.common.SPP                       [256, 256, [5, 9, 13]]        \n",
      " 25                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 26          [22, 25]  1   6351360  models.common.GPT                       [256]                         \n",
      " 27          [22, 26]  1         0  models.common.Add2                      [256, 0]                      \n",
      " 28          [25, 26]  1         0  models.common.Add2                      [256, 1]                      \n",
      " 29          [11, 12]  1         0  models.common.Add                       [64]                          \n",
      " 30          [18, 19]  1         0  models.common.Add                       [128]                         \n",
      " 31          [27, 28]  1         0  models.common.Add                       [256]                         \n",
      " 32                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 33                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 34          [-1, 30]  1         0  models.common.Concat                    [1]                           \n",
      " 35                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 36                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      " 37                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 38          [-1, 29]  1         0  models.common.Concat                    [1]                           \n",
      " 39                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 40                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 41          [-1, 36]  1         0  models.common.Concat                    [1]                           \n",
      " 42                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
      " 43                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 44          [-1, 32]  1         0  models.common.Concat                    [1]                           \n",
      " 45                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 46      [39, 42, 45]  1      9471  models.yolo_test.Detect                 [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
      "Model Summary: 829 layers, 11196095 parameters, 11196095 gradients\n",
      "\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 292 .bias, 292 conv.weight, 94 other\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning RGB '../datasets/PLVIS2D/labels/train.rgb.cache' images and labels... 996 found, 0 missing, 50 empty, 0 corrupted\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning IR '../datasets/PLVIS2D/labels/train.ir.cache' images and labels... 996 found, 0 missing, 50 empty, 0 corrupted\n",
      "1.0\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning RGB '../datasets/PLVIS2D/labels/val.rgb.cache' images and labels... 109 found, 0 missing, 6 empty, 0 corrupted\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning IR '../datasets/PLVIS2D/labels/val.ir.cache' images and labels... 109 found, 0 missing, 6 empty, 0 corrupted\n",
      "Plotting labels... \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 1012, in <module>\n",
      "    train_rgb_ir(hyp, opt, device, tb_writer)\n",
      "  File \"train.py\", line 645, in train_rgb_ir\n",
      "    plot_labels(labels, names, save_dir, loggers)\n",
      "  File \"/home/ubuntu/multispectral-object-detection/utils/plots.py\", line 296, in plot_labels\n",
      "    sns.pairplot(x, corner=True, diag_kind='auto', kind='hist', diag_kws=dict(bins=50), plot_kws=dict(pmax=0.9))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/seaborn/_decorators.py\", line 46, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/seaborn/axisgrid.py\", line 1991, in pairplot\n",
      "    height=height, aspect=aspect, dropna=dropna, **grid_kws)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/seaborn/_decorators.py\", line 46, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/seaborn/axisgrid.py\", line 1186, in __init__\n",
      "    squeeze=False)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\", line 451, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 1290, in subplots\n",
      "    gridspec_kw=gridspec_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\", line 451, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/figure.py\", line 1524, in subplots\n",
      "    subplot_kw=subplot_kw))\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/gridspec.py\", line 337, in subplots\n",
      "    self[row, col], **subplot_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/figure.py\", line 1402, in add_subplot\n",
      "    ax = subplot_class_factory(projection_class)(self, *args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axes/_subplots.py\", line 42, in __init__\n",
      "    self._axes_class.__init__(self, fig, self.figbox, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 511, in __init__\n",
      "    self.cla()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axes/_base.py\", line 1162, in cla\n",
      "    self.yaxis.set_clip_path(self.patch)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axis.py\", line 901, in set_clip_path\n",
      "    for child in self.majorTicks + self.minorTicks:\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axis.py\", line 623, in __get__\n",
      "    tick = instance._get_tick(major=False)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axis.py\", line 2306, in _get_tick\n",
      "    return YTick(self.axes, 0, major=major, **tick_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/axis.py\", line 495, in __init__\n",
      "    marker=self._tickmarkers[0],\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/artist.py\", line 1088, in set\n",
      "    kwargs = cbook.normalize_kwargs(kwargs, self)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\", line 400, in wrapper\n",
      "    for d in [arguments, arguments.get(kwargs_name, {})]):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py --img 640 --batch 32 --epochs 100 --adam \\\n",
    "--data PLVIS2D.yaml --cfg models/transformer/yolov5n_fusion_transformerx3.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ad54890-fa9e-4998-9794-9a4fb4c280b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = \"       0/0     2.04G    0.1043    0.0253   0.02532    0.1549         9       640 \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46b30ee1-a0e5-450e-9c97-a7335e3f2e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0/0, 2.04G, 0.1043, 0.0253, 0.02532, 0.1549, 9, 640'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "', '.join(list(filter(None,dum.split(' '))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa81b302-605c-4522-9bb2-a91543d02cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: switchml: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `switchml'\n",
      "/bin/bash: _moduleraw: line 1: syntax error: unexpected end of file\n",
      "/bin/bash: error importing function definition for `_moduleraw'\n",
      "Namespace(augment=False, batch_size=64, conf_thres=0.001, data='./data/multispectral/PLVIS2D.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.5, name='exp', project='runs/test', save_conf=True, save_hybrid=False, save_json=False, save_txt=True, single_cls=False, task='val', verbose=False, weights=['runs/train/exp3/weights/best.pt'])\n",
      "./data/multispectral/PLVIS2D.yaml\n",
      "YOLOv5 ðŸš€ bb2b687 torch 1.8.1+cu111 CUDA:0 (Tesla T4, 15109.75MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 735 layers, 11188575 parameters, 0 gradients\n",
      "val\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning RGB '../datasets/PLVIS2D/labels/val.rgb.cache' images and labels... 109 found, 0 missing, 6 empty, 0 corrupted\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning IR '../datasets/PLVIS2D/labels/val.ir.cache' images and labels... 109 found, 0 missing, 6 empty, 0 corrupted\n",
      "               Class      Images      Labels           P           R      mAP@.5/home/ubuntu/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
      "               Class      Images      Labels           P           R      mAP@.5\n",
      "                 all         109         125       0.858       0.928       0.887       0.623       0.491\n",
      "                Dirt         109          21       0.987           1       0.995       0.995       0.647\n",
      "                  ML         109         104       0.729       0.856       0.778       0.251       0.335\n",
      "Speed: 5.3/0.9/6.3 ms inference/NMS/total per 640x640 image at batch-size 64\n",
      "Results saved to runs/test/exp3\n",
      "109 labels saved to runs/test/exp3/labels\n"
     ]
    }
   ],
   "source": [
    "!python3 test.py --data PLVIS2D.yaml --weights runs/train/exp3/weights/best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4736f43-3e8a-4b60-ad82-2fb8d893f01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
